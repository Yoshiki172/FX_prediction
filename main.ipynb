{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import mplfinance as mpf\n",
    "from sklearn import model_selection\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-23</th>\n",
       "      <td>126.980003</td>\n",
       "      <td>127.110001</td>\n",
       "      <td>126.519997</td>\n",
       "      <td>126.879997</td>\n",
       "      <td>126.879997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-24</th>\n",
       "      <td>126.900002</td>\n",
       "      <td>127.760002</td>\n",
       "      <td>126.800003</td>\n",
       "      <td>127.489998</td>\n",
       "      <td>127.489998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-27</th>\n",
       "      <td>127.589996</td>\n",
       "      <td>128.940002</td>\n",
       "      <td>127.489998</td>\n",
       "      <td>128.440002</td>\n",
       "      <td>128.440002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-28</th>\n",
       "      <td>128.460007</td>\n",
       "      <td>128.720001</td>\n",
       "      <td>128.020004</td>\n",
       "      <td>128.470001</td>\n",
       "      <td>128.470001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-29</th>\n",
       "      <td>128.460007</td>\n",
       "      <td>128.619995</td>\n",
       "      <td>127.889999</td>\n",
       "      <td>128.279999</td>\n",
       "      <td>128.279999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  Volume\n",
       "Date                                                                          \n",
       "2003-01-23  126.980003  127.110001  126.519997  126.879997  126.879997       0\n",
       "2003-01-24  126.900002  127.760002  126.800003  127.489998  127.489998       0\n",
       "2003-01-27  127.589996  128.940002  127.489998  128.440002  128.440002       0\n",
       "2003-01-28  128.460007  128.720001  128.020004  128.470001  128.470001       0\n",
       "2003-01-29  128.460007  128.619995  127.889999  128.279999  128.279999       0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = yf.download('EURJPY=X', start='2001-01-03', end='2021-03-09')\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yt-in\\AppData\\Local\\Temp\\ipykernel_4012\\710805594.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Up'][i] = 1\n"
     ]
    }
   ],
   "source": [
    "data['Up'] = 0\n",
    "# future_num日後の終値の上下を予測\n",
    "future_num = 1\n",
    "for i in range(len(data)-1):\n",
    "    if data['Close'][i] < data['Close'][i+future_num]:\n",
    "        data['Up'][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ImageName'] =  ['./DataFolder/' + str(data.index[i].year)+ '-'  + str(data.index[i].month) + '-' + str(data.index[i].day) + '.png' for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting olhc to candlestik finished.\n"
     ]
    }
   ],
   "source": [
    "img_create = 1\n",
    "if img_create == 1:\n",
    "    seq_len = 20\n",
    "\n",
    "    data.fillna(0)\n",
    "    #data.reset_index(inplace=True)\n",
    "    data['Date2'] = data.index\n",
    "    data['Date2'] = data['Date2'].map(mdates.date2num)\n",
    "    for i in range(0, len(data)-1):\n",
    "        c = data.iloc[i:i + int(seq_len) , :]\n",
    "        if len(c) == int(seq_len):\n",
    "            # Date,Open,High,Low,Adj Close,Volume\n",
    "            target = ['Date2','Open','High','Low','Close']\n",
    "            pngfile = data['ImageName'][i + int(seq_len)-2]\n",
    "\n",
    "            my_dpi = 96\n",
    "            # Create my own `marketcolors` to use with the `nightclouds` style:\n",
    "            mc = mpf.make_marketcolors(up='#77d879',down='#db3f3f',inherit=True)\n",
    "\n",
    "            # Create a new style based on `nightclouds` but with my own `marketcolors`:\n",
    "            s  = mpf.make_mpf_style(base_mpf_style='nightclouds',marketcolors=mc,gridstyle = '')\n",
    "\n",
    "            fig = mpf.figure(style=s,figsize=(48 / my_dpi, 48 / my_dpi), dpi=my_dpi)\n",
    "            ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "            ax1.grid(False)\n",
    "            ax1.set_xticklabels([])\n",
    "            ax1.set_yticklabels([])\n",
    "            ax1.xaxis.set_visible(False)\n",
    "            ax1.yaxis.set_visible(False)\n",
    "            ax1.axis('off')\n",
    "\n",
    "            mpf.plot(c[target], ax=ax1,volume=False,type='candle',update_width_config=dict(candle_linewidth=1))\n",
    "            fig.savefig(pngfile,  pad_inches=0, transparent=False, bbox_inches=\"tight\")\n",
    "\n",
    "            plt.close(fig)\n",
    "\n",
    "\n",
    "    print(\"Converting olhc to candlestik finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(data['ImageName'].values, data['Up'].values, test_size=0.1,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './DataFolder/2003-1-24.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-2-10.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-1-31.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2021-3-8.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-1-28.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-2-3.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-1-29.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-2-7.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-2-6.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-2-14.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-2-4.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-1-23.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-2-5.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-1-27.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-1-30.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-2-12.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-2-13.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-2-11.png'\n",
      "[Errno 2] No such file or directory: './DataFolder/2003-2-17.png'\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "X_val = []\n",
    "Y_val = []\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "#for image_file,label in zip(x_train,y_train):\n",
    "for image_file,label in zip(x_train,y_train):\n",
    "    try:\n",
    "        image = Image.open(image_file)\n",
    "        image = image.convert('RGB')\n",
    "        image = transform(image)\n",
    "        #image = np.asarray(image)\n",
    "        X.append(image)\n",
    "        Y.append(label)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "for image_file,label in zip(x_val,y_val):\n",
    "    try:\n",
    "        image = Image.open(image_file)\n",
    "        image = image.convert('RGB')\n",
    "        image = transform(image)\n",
    "        X_val.append(image)\n",
    "        Y_val.append(label)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EUR_Dataset(Dataset):\n",
    "    def __init__(self, image, label_list, phase=None):\n",
    "\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        self.image = image\n",
    "        self.label_list = torch.tensor(label_list,dtype=torch.long)\n",
    "        self.phase = phase\n",
    "\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        # index番目の画像を読み込み、前処理を行う\n",
    "        image = self.image[index]\n",
    "        # index番目のラベルを取得する\n",
    "        label = self.label_list[index]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4214\n",
      "469\n"
     ]
    }
   ],
   "source": [
    "train_dataset = EUR_Dataset(X,Y,phase='train')\n",
    "total_samples = len(train_dataset)\n",
    "print(total_samples)\n",
    "val_dataset = EUR_Dataset(X_val,Y_val,phase='val')\n",
    "val_samples = len(val_dataset)\n",
    "print(val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.resnet18(pretrained=False)\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "model.fc  = nn.Sequential(\n",
    "                      nn.Linear(num_ftrs ,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.AdamW(model.parameters())\n",
    "\n",
    "batchsize = 16\n",
    "\n",
    "loss_list = []\n",
    "val_loss_list = []\n",
    "# DataLoaderのインスタンス作成\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batchsize, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=batchsize, shuffle=True)\n",
    "\n",
    "# データローダーを辞書として格納する\n",
    "dataloaders_dict = {\n",
    "    'train' : train_dataloader,\n",
    "    'val' : val_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_loss = []\n",
    "Val_loss = []\n",
    "Train_acc = []\n",
    "Val_acc = []\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer,  num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    #best_acc = 0.0\n",
    "    best_loss = 1000.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 学習モード、検証モードの切替\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            #for i,data in enumerate(trainloader):\n",
    "            i = 0\n",
    "            data_num = 0\n",
    "            for inputs, labels in dataloaders_dict[phase]:\n",
    "                i += 1\n",
    "                #for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.argmax(outputs, axis=1)\n",
    "\n",
    "                    #print(preds)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                    data_num += inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss/data_num\n",
    "            epoch_acc = running_corrects.double()/data_num\n",
    "\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'train':\n",
    "                Train_loss.append(epoch_loss)\n",
    "                Train_acc.append(epoch_acc)\n",
    "            else:\n",
    "                Val_loss.append(epoch_loss)\n",
    "                Val_acc.append(epoch_acc)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 0.5645 Acc: 0.7100\n",
      "val Loss: 0.3841 Acc: 0.8252\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yt-in\\Desktop\\お勉強\\FX\\main.ipynb Cell 19\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yt-in/Desktop/%E3%81%8A%E5%8B%89%E5%BC%B7/FX/main.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m train_model(model,criterion,optimizer_ft,num_epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\yt-in\\Desktop\\お勉強\\FX\\main.ipynb Cell 19\u001b[0m line \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yt-in/Desktop/%E3%81%8A%E5%8B%89%E5%BC%B7/FX/main.ipynb#X24sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# backward + optimize only if in training phase\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yt-in/Desktop/%E3%81%8A%E5%8B%89%E5%BC%B7/FX/main.ipynb#X24sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mif\u001b[39;00m phase \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yt-in/Desktop/%E3%81%8A%E5%8B%89%E5%BC%B7/FX/main.ipynb#X24sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yt-in/Desktop/%E3%81%8A%E5%8B%89%E5%BC%B7/FX/main.ipynb#X24sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yt-in/Desktop/%E3%81%8A%E5%8B%89%E5%BC%B7/FX/main.ipynb#X24sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# statistics\u001b[39;00m\n",
      "File \u001b[1;32mc:\\pg\\Python38\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\pg\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train_model(model,criterion,optimizer_ft,num_epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
